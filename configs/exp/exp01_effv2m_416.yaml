# @package exp

name: exp01_effv2m_416
input:
  size:
    - 416
    - 416
  use_pseudo: false
model:
  seed: 0
  backbone: efficientnetv2_rw_m
  pretrained: true
  do_dropout: true
  hidden_dim: 512
training:
  batch_size : 12
  epochs: 59  # 3.5 cycles (8 * 2 * 3.5) + 3 epochs
  learning_rate: 1e-3
  optimizer: adamw
  weight_decay: 1e-2
  verbose_epochs: 10
  log_every_n_steps: 10  # default=50
  criterion: 
    loss_function: LabelSmoothingCrossEntropy
    smoothing: 0.1
lrate_scheduler:
  scheduler: LinearWarmupCosineAnnealingLR
  T_max: 2136  # 8 epochs x 267 mini-batches (3215 // 12)
  warmup_epochs: 801  # 3 epochs x 267 batches
  warmup_start_lr: 0.0
  eta_min: 0.0
  m_mul: 1.0
tta:
  batch_size : 20
  size: 540  # 416 * 1.3