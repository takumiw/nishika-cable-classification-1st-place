# @package exp

name: exp23_effb7_600
input:
  size:
    - 600
    - 600
  use_pseudo: true
model:
  seed: 0
  backbone: efficientnet_b7
  pretrained: true
  do_dropout: true
  hidden_dim: null
training:
  batch_size: 3
  epochs: 46  # 5.5 cycles (4 * 2 * 5.5) + 2 epochs
  learning_rate: 1e-3
  optimizer: adamw
  weight_decay: 1e-2
  verbose_epochs: 10
  log_every_n_steps: 10  # default=50
  criterion: 
    loss_function: LabelSmoothingCrossEntropy
    smoothing: 0.1
lrate_scheduler:
  scheduler: LinearWarmupCosineAnnealingLR
  T_max: 5892  # 4 epochs x 1473 mini-batches (4420 // 3)
  warmup_epochs: 2946  # 2 epochs x 1473 batches
  warmup_start_lr: 0.0
  eta_min: 0.0
  m_mul: 0.8
tta:
  batch_size : 4
  size: 494  # 380 * 1.3
  transforms:
    - HorizontalFlip
    - VerticalFlip
    - Scale
    - Rotate90
    - Multiply
  settings:
    scales:
      - 1.0
      - 0.83
      - 0.67
    angles:
      - 0
      - 90
      - 270
    factors:
      - 0.9
      - 1.0
      - 1.1