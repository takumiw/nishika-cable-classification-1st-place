# @package exp

name: exp24_effv2m_416
input:
  size:
    - 416
    - 416
  use_pseudo: true
model:
  seed: 0
  backbone: efficientnetv2_rw_m
  pretrained: true
  do_dropout: true
  hidden_dim: 512
training:
  batch_size : 12
  epochs: 46  # 5.5 cycles (4 * 2 * 5.5) + 2 epochs
  learning_rate: 1e-3
  optimizer: adamw
  weight_decay: 1e-2
  verbose_epochs: 10
  log_every_n_steps: 10  # default=50
  criterion: 
    loss_function: LabelSmoothingCrossEntropy
    smoothing: 0.1
lrate_scheduler:
  scheduler: LinearWarmupCosineAnnealingLR
  T_max: 1472  # 4 epochs x 368 mini-batches (4420 // 12)
  warmup_epochs: 736  # 2 epochs x 368 batches
  warmup_start_lr: 0.0
  eta_min: 0.0
  m_mul: 0.8
tta:
  batch_size : 20
  size: 540  # 416 * 1.3